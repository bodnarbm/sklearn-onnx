
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_tutorial/plot_dbegin_options_zipmap.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_tutorial_plot_dbegin_options_zipmap.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_tutorial_plot_dbegin_options_zipmap.py:


.. _l-tutorial-example-zipmap:

Choose appropriate output of a classifier
=========================================

A scikit-learn classifier usually returns a matrix of probabilities.
By default, *sklearn-onnx* converts that matrix
into a list of dictionaries where each probabily is mapped
to its class id or name. That mechanism retains the class names
but is slower. Let's see what other options are available.

Train a model and convert it
++++++++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 20-44

.. code-block:: default

    from timeit import repeat
    import numpy
    import sklearn
    from sklearn.datasets import load_iris
    from sklearn.model_selection import train_test_split
    import onnxruntime as rt
    import onnx
    import skl2onnx
    from skl2onnx.common.data_types import FloatTensorType
    from skl2onnx import to_onnx
    from sklearn.linear_model import LogisticRegression
    from sklearn.multioutput import MultiOutputClassifier

    iris = load_iris()
    X, y = iris.data, iris.target
    X = X.astype(numpy.float32)
    y = y * 2 + 10  # to get labels different from [0, 1, 2]
    X_train, X_test, y_train, y_test = train_test_split(X, y)
    clr = LogisticRegression(max_iter=500)
    clr.fit(X_train, y_train)
    print(clr)

    onx = to_onnx(clr, X_train, target_opset=12)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    LogisticRegression(max_iter=500)




.. GENERATED FROM PYTHON SOURCE LINES 45-50

Default behaviour: zipmap=True
++++++++++++++++++++++++++++++

The output type for the probabilities is a list of
dictionaries.

.. GENERATED FROM PYTHON SOURCE LINES 50-57

.. code-block:: default


    sess = rt.InferenceSession(onx.SerializeToString())
    res = sess.run(None, {'X': X_test})
    print(res[1][:2])
    print("probabilities type:", type(res[1]))
    print("type for the first observations:", type(res[1][0]))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [{10: 0.02909434586763382, 12: 0.9069037437438965, 14: 0.06400192528963089}, {10: 0.001469946000725031, 12: 0.6960583329200745, 14: 0.30247175693511963}]
    probabilities type: <class 'list'>
    type for the first observations: <class 'dict'>




.. GENERATED FROM PYTHON SOURCE LINES 58-62

Option zipmap=False
+++++++++++++++++++

Probabilities are now a matrix.

.. GENERATED FROM PYTHON SOURCE LINES 62-73

.. code-block:: default


    initial_type = [('float_input', FloatTensorType([None, 4]))]
    options = {id(clr): {'zipmap': False}}
    onx2 = to_onnx(clr, X_train, options=options, target_opset=12)

    sess2 = rt.InferenceSession(onx2.SerializeToString())
    res2 = sess2.run(None, {'X': X_test})
    print(res2[1][:2])
    print("probabilities type:", type(res2[1]))
    print("type for the first observations:", type(res2[1][0]))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [[0.02909435 0.90690374 0.06400193]
     [0.00146995 0.69605833 0.30247176]]
    probabilities type: <class 'numpy.ndarray'>
    type for the first observations: <class 'numpy.ndarray'>




.. GENERATED FROM PYTHON SOURCE LINES 74-80

Option zipmap='columns'
+++++++++++++++++++++++

This options removes the final operator ZipMap and splits
the probabilities into columns. The final model produces
one output for the label, and one output per class.

.. GENERATED FROM PYTHON SOURCE LINES 80-91

.. code-block:: default


    options = {id(clr): {'zipmap': 'columns'}}
    onx3 = to_onnx(clr, X_train, options=options, target_opset=12)

    sess3 = rt.InferenceSession(onx3.SerializeToString())
    res3 = sess3.run(None, {'X': X_test})
    for i, out in enumerate(sess3.get_outputs()):
        print("output: '{}' shape={} values={}...".format(
            out.name, res3[i].shape, res3[i][:2]))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    output: 'output_label' shape=(38,) values=[12 12]...
    output: 'i10' shape=(38,) values=[0.02909435 0.00146995]...
    output: 'i12' shape=(38,) values=[0.90690374 0.69605833]...
    output: 'i14' shape=(38,) values=[0.06400193 0.30247176]...




.. GENERATED FROM PYTHON SOURCE LINES 92-94

Let's compare prediction time
+++++++++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 94-114

.. code-block:: default


    print("Average time with ZipMap:")
    print(sum(repeat(lambda: sess.run(None, {'X': X_test}),
                     number=100, repeat=10)) / 10)

    print("Average time without ZipMap:")
    print(sum(repeat(lambda: sess2.run(None, {'X': X_test}),
                     number=100, repeat=10)) / 10)

    print("Average time without ZipMap but with columns:")
    print(sum(repeat(lambda: sess3.run(None, {'X': X_test}),
                     number=100, repeat=10)) / 10)

    # The prediction is much faster without ZipMap
    # on this example.
    # The optimisation is even faster when the classes
    # are described with strings and not integers
    # as the final result (list of dictionaries) may copy
    # many times the same information with onnxruntime.





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Average time with ZipMap:
    0.003929830000015499
    Average time without ZipMap:
    0.0014273400999172737
    Average time without ZipMap but with columns:
    0.002505180000025575




.. GENERATED FROM PYTHON SOURCE LINES 115-122

Option zimpap=False and output_class_labels=True
++++++++++++++++++++++++++++++++++++++++++++++++

Option `zipmap=False` seems a better choice because it is
much faster but labels are lost in the process. Option
`output_class_labels` can be used to expose the labels
as a third output.

.. GENERATED FROM PYTHON SOURCE LINES 122-133

.. code-block:: default


    initial_type = [('float_input', FloatTensorType([None, 4]))]
    options = {id(clr): {'zipmap': False, 'output_class_labels': True}}
    onx4 = to_onnx(clr, X_train, options=options, target_opset=12)

    sess4 = rt.InferenceSession(onx4.SerializeToString())
    res4 = sess4.run(None, {'X': X_test})
    print(res4[1][:2])
    print("probabilities type:", type(res4[1]))
    print("class labels:", res4[2])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [[0.02909435 0.90690374 0.06400193]
     [0.00146995 0.69605833 0.30247176]]
    probabilities type: <class 'numpy.ndarray'>
    class labels: [10 12 14]




.. GENERATED FROM PYTHON SOURCE LINES 134-135

Processing time.

.. GENERATED FROM PYTHON SOURCE LINES 135-140

.. code-block:: default


    print("Average time without ZipMap but with output_class_labels:")
    print(sum(repeat(lambda: sess4.run(None, {'X': X_test}),
                     number=100, repeat=10)) / 10)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Average time without ZipMap but with output_class_labels:
    0.002399530100001357




.. GENERATED FROM PYTHON SOURCE LINES 141-148

MultiOutputClassifier
+++++++++++++++++++++

This model is equivalent to several classifiers, one for every label
to predict. Instead of returning a matrix of probabilities, it returns
a sequence of matrices. Let's first modify the labels to get
a problem for a MultiOutputClassifier.

.. GENERATED FROM PYTHON SOURCE LINES 148-153

.. code-block:: default


    y = numpy.vstack([y, y + 100]).T
    y[::5, 1] = 1000  # Let's a fourth class.
    print(y[:5])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [[  10 1000]
     [  10  110]
     [  10  110]
     [  10  110]
     [  10  110]]




.. GENERATED FROM PYTHON SOURCE LINES 154-155

Let's train a MultiOutputClassifier.

.. GENERATED FROM PYTHON SOURCE LINES 155-167

.. code-block:: default


    X_train, X_test, y_train, y_test = train_test_split(X, y)
    clr = MultiOutputClassifier(LogisticRegression(max_iter=500))
    clr.fit(X_train, y_train)
    print(clr)

    onx5 = to_onnx(clr, X_train, target_opset=12)

    sess5 = rt.InferenceSession(onx5.SerializeToString())
    res5 = sess5.run(None, {'X': X_test[:3]})
    print(res5)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    MultiOutputClassifier(estimator=LogisticRegression(max_iter=500))
    /home/xadupre/github/sklearn-onnx/skl2onnx/_parse.py:529: UserWarning: Option zipmap is ignored for model <class 'sklearn.multioutput.MultiOutputClassifier'>. Set option zipmap to False to remove this message.
      warnings.warn(
    [array([[ 10, 110],
           [ 10, 110],
           [ 10, 110]], dtype=int64), [array([[9.5487159e-01, 4.5127936e-02, 4.7449998e-07],
           [9.7273737e-01, 2.7262522e-02, 1.5831836e-07],
           [9.6799171e-01, 3.2008070e-02, 2.2276080e-07]], dtype=float32), array([[7.2772932e-01, 8.8738047e-02, 1.0638156e-04, 1.8342626e-01],
           [8.3462042e-01, 6.5695420e-02, 6.4909793e-05, 9.9619307e-02],
           [7.9595613e-01, 6.4299725e-02, 6.8941692e-05, 1.3967523e-01]],
          dtype=float32)]]




.. GENERATED FROM PYTHON SOURCE LINES 168-170

Option zipmap is ignored. Labels are missing but they can be
added back as a third output.

.. GENERATED FROM PYTHON SOURCE LINES 170-181

.. code-block:: default


    onx6 = to_onnx(clr, X_train, target_opset=12,
                   options={'zipmap': False, 'output_class_labels': True})

    sess6 = rt.InferenceSession(onx6.SerializeToString())
    res6 = sess6.run(None, {'X': X_test[:3]})
    print("predicted labels", res6[0])
    print("predicted probabilies", res6[1])
    print("class labels", res6[2])






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    predicted labels [[ 10 110]
     [ 10 110]
     [ 10 110]]
    predicted probabilies [array([[9.5487159e-01, 4.5127936e-02, 4.7449998e-07],
           [9.7273737e-01, 2.7262522e-02, 1.5831836e-07],
           [9.6799171e-01, 3.2008070e-02, 2.2276080e-07]], dtype=float32), array([[7.2772932e-01, 8.8738047e-02, 1.0638156e-04, 1.8342626e-01],
           [8.3462042e-01, 6.5695420e-02, 6.4909793e-05, 9.9619307e-02],
           [7.9595613e-01, 6.4299725e-02, 6.8941692e-05, 1.3967523e-01]],
          dtype=float32)]
    class labels [array([10, 12, 14], dtype=int64), array([ 110,  112,  114, 1000], dtype=int64)]




.. GENERATED FROM PYTHON SOURCE LINES 182-183

**Versions used for this example**

.. GENERATED FROM PYTHON SOURCE LINES 183-189

.. code-block:: default


    print("numpy:", numpy.__version__)
    print("scikit-learn:", sklearn.__version__)
    print("onnx: ", onnx.__version__)
    print("onnxruntime: ", rt.__version__)
    print("skl2onnx: ", skl2onnx.__version__)




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    numpy: 1.23.5
    scikit-learn: 1.3.dev0
    onnx:  1.14.0
    onnxruntime:  1.15.0+cpu
    skl2onnx:  1.14.0





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.267 seconds)


.. _sphx_glr_download_auto_tutorial_plot_dbegin_options_zipmap.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_dbegin_options_zipmap.py <plot_dbegin_options_zipmap.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_dbegin_options_zipmap.ipynb <plot_dbegin_options_zipmap.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
